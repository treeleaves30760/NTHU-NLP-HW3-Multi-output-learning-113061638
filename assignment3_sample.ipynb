{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hsupohsiang/Desktop/Self/NLP/HW3/NTHU-NLP-HW3-Multi-output-learning-113061638/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import transformers as T\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from torchmetrics import SpearmanCorrCoef, Accuracy, F1Score\n",
    "from transformers import BertModel\n",
    "import torch.nn as nn\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 有些中文的標點符號在tokenizer編碼以後會變成[UNK]，所以將其換成英文標點\n",
    "token_replacement = [\n",
    "    [\"：\" , \":\"],\n",
    "    [\"，\" , \",\"],\n",
    "    [\"“\" , \"\\\"\"],\n",
    "    [\"”\" , \"\\\"\"],\n",
    "    [\"？\" , \"?\"],\n",
    "    [\"……\" , \"...\"],\n",
    "    [\"！\" , \"!\"]\n",
    "]\n",
    "\n",
    "tokenizer = T.BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\", cache_dir=\"./cache/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset example: \n",
      "{'sentence_pair_id': 1, 'premise': 'A group of kids is playing in a yard and an old man is standing in the background', 'hypothesis': 'A group of boys in a yard is playing and a man is standing in the background', 'relatedness_score': 4.5, 'entailment_judgment': 0} \n",
      "{'sentence_pair_id': 2, 'premise': 'A group of children is playing in the house and there is no man standing in the background', 'hypothesis': 'A group of kids is playing in a yard and an old man is standing in the background', 'relatedness_score': 3.200000047683716, 'entailment_judgment': 0} \n",
      "{'sentence_pair_id': 3, 'premise': 'The young boys are playing outdoors and the man is smiling nearby', 'hypothesis': 'The kids are playing outdoors near a man with a smile', 'relatedness_score': 4.699999809265137, 'entailment_judgment': 1}\n"
     ]
    }
   ],
   "source": [
    "class SemevalDataset(Dataset):\n",
    "    def __init__(self, split=\"train\") -> None:\n",
    "        super().__init__()\n",
    "        assert split in [\"train\", \"validation\"]\n",
    "        self.data = load_dataset(\n",
    "            \"sem_eval_2014_task_1\", split=split, cache_dir=\"./cache/\"\n",
    "        ).to_list()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        d = self.data[index]\n",
    "        # 把中文標點替換掉\n",
    "        for k in [\"premise\", \"hypothesis\"]:\n",
    "            for tok in token_replacement:\n",
    "                d[k] = d[k].replace(tok[0], tok[1])\n",
    "        return d\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "data_sample = SemevalDataset(split=\"train\").data[:3]\n",
    "print(f\"Dataset example: \\n{data_sample[0]} \\n{data_sample[1]} \\n{data_sample[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "lr = 3e-5\n",
    "epochs = 3\n",
    "train_batch_size = 8\n",
    "validation_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO1: Create batched data for DataLoader\n",
    "# `collate_fn` is a function that defines how the data batch should be packed.\n",
    "# This function will be called in the DataLoader to pack the data batch.\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Get premise and hypothesis texts\n",
    "    premises = [d['premise'] for d in batch]\n",
    "    hypotheses = [d['hypothesis'] for d in batch]\n",
    "    \n",
    "    # Concatenate premise and hypothesis with [SEP] token for BERT input\n",
    "    text_pairs = list(zip(premises, hypotheses))\n",
    "    \n",
    "    # Tokenize using BERT tokenizer\n",
    "    encoded = tokenizer.batch_encode_plus(\n",
    "        text_pairs,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Get labels - fix the key name here\n",
    "    relatedness_scores = torch.tensor([d['relatedness_score'] for d in batch], dtype=torch.float)\n",
    "    entailment_labels = torch.tensor([d['entailment_judgment'] for d in batch], dtype=torch.long)\n",
    "    \n",
    "    return (\n",
    "        encoded['input_ids'], \n",
    "        encoded['attention_mask'],\n",
    "        encoded['token_type_ids'],\n",
    "        relatedness_scores,\n",
    "        entailment_labels\n",
    "    )\n",
    "\n",
    "# Create DataLoaders\n",
    "dl_train = DataLoader(\n",
    "    SemevalDataset(split=\"train\"),\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "dl_validation = DataLoader(\n",
    "    SemevalDataset(split=\"validation\"),\n",
    "    batch_size=validation_batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO2: Construct your model\n",
    "\n",
    "class MultiOutputModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiOutputModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.regressor = nn.Linear(self.bert.config.hidden_size, 1)  # Regression task\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 3)  # Classification task\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        bert_output = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        hidden_state = bert_output.pooler_output\n",
    "        relatedness_score = self.regressor(hidden_state)\n",
    "        entailment_judgement = self.classifier(hidden_state)\n",
    "        return relatedness_score, entailment_judgement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiOutputModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hsupohsiang/Desktop/Self/NLP/HW3/NTHU-NLP-HW3-Multi-output-learning-113061638/.conda/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "# TODO3: Define your optimizer and loss function\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "# Loss functions\n",
    "regression_loss = nn.MSELoss()  # For relatedness score regression\n",
    "classification_loss = nn.CrossEntropyLoss()  # For entailment classification\n",
    "\n",
    "# scoring functions\n",
    "spc = SpearmanCorrCoef()\n",
    "acc = Accuracy(task=\"multiclass\", num_classes=3)\n",
    "f1 = F1Score(task=\"multiclass\", num_classes=3, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    all_rel_preds = []\n",
    "    all_rel_true = []\n",
    "    all_ent_preds = []\n",
    "    all_ent_true = []\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        # Unpack batch and move to device\n",
    "        input_ids, attention_mask, token_type_ids, rel_scores, ent_labels = [\n",
    "            x.to(device) for x in batch\n",
    "        ]\n",
    "        \n",
    "        # Forward pass\n",
    "        rel_pred, ent_pred = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        # Store predictions and true labels\n",
    "        all_rel_preds.extend(rel_pred.squeeze().cpu().tolist())\n",
    "        all_rel_true.extend(rel_scores.cpu().tolist())\n",
    "        all_ent_preds.extend(ent_pred.argmax(dim=-1).cpu().tolist())\n",
    "        all_ent_true.extend(ent_labels.cpu().tolist())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rel_preds = torch.tensor(all_rel_preds)\n",
    "    rel_true = torch.tensor(all_rel_true)\n",
    "    ent_preds = torch.tensor(all_ent_preds)\n",
    "    ent_true = torch.tensor(all_ent_true)\n",
    "    \n",
    "    spearman = spc(rel_preds, rel_true)\n",
    "    accuracy = acc(ent_preds, ent_true)\n",
    "    f1_macro = f1(ent_preds, ent_true)\n",
    "    \n",
    "    return {\n",
    "        'spearman': spearman.item(),\n",
    "        'accuracy': accuracy.item(),\n",
    "        'f1_macro': f1_macro.item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation epoch [1/3]:   0%|          | 0/63 [15:39<?, ?it/s]\n",
      "Training epoch [1/3]: 100%|██████████| 563/563 [06:44<00:00,  1.39it/s, rel_loss=0.3444, ent_loss=1.6482]\n",
      "Validation epoch [1/3]:   0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Validation Metrics:\n",
      "Spearman: 0.8245\n",
      "Accuracy: 0.8800\n",
      "F1-macro: 0.8762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation epoch [1/3]:   0%|          | 0/63 [00:17<?, ?it/s]\n",
      "Training epoch [2/3]: 100%|██████████| 563/563 [08:14<00:00,  1.14it/s, rel_loss=0.1713, ent_loss=0.0855]\n",
      "Validation epoch [2/3]:   0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Validation Metrics:\n",
      "Spearman: 0.8230\n",
      "Accuracy: 0.8540\n",
      "F1-macro: 0.8564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation epoch [2/3]:   0%|          | 0/63 [00:39<?, ?it/s]\n",
      "Training epoch [3/3]: 100%|██████████| 563/563 [09:42<00:00,  1.03s/it, rel_loss=0.1916, ent_loss=0.0523]\n",
      "Validation epoch [3/3]:   0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Validation Metrics:\n",
      "Spearman: 0.8238\n",
      "Accuracy: 0.8640\n",
      "F1-macro: 0.8609\n"
     ]
    }
   ],
   "source": [
    "for ep in range(epochs):\n",
    "    pbar = tqdm(dl_train)\n",
    "    pbar.set_description(f\"Training epoch [{ep+1}/{epochs}]\")\n",
    "    model.train()\n",
    "    # TODO4: Write the training loop\n",
    "    \n",
    "    for batch in pbar:\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Unpack batch and move to device\n",
    "        input_ids, attention_mask, token_type_ids, rel_scores, ent_labels = [\n",
    "            x.to(device) for x in batch\n",
    "        ]\n",
    "        \n",
    "        # Forward pass\n",
    "        rel_pred, ent_pred = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        # Calculate losses\n",
    "        loss_rel = regression_loss(rel_pred.squeeze(), rel_scores)\n",
    "        loss_ent = classification_loss(ent_pred, ent_labels)\n",
    "        \n",
    "        # Combine losses\n",
    "        total_loss = loss_rel + loss_ent\n",
    "        \n",
    "        # Backward pass\n",
    "        total_loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'rel_loss': f'{loss_rel.item():.4f}',\n",
    "            'ent_loss': f'{loss_ent.item():.4f}'\n",
    "        })\n",
    "    \n",
    "    pbar = tqdm(dl_validation)\n",
    "    pbar.set_description(f\"Validation epoch [{ep+1}/{epochs}]\")\n",
    "    model.eval()\n",
    "    # TODO5: Write the evaluation loop\n",
    "    metrics = evaluate(model, dl_validation)\n",
    "\n",
    "    print(f\"Epoch {ep+1} Validation Metrics:\")\n",
    "    print(f\"Spearman: {metrics['spearman']:.4f}\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"F1-macro: {metrics['f1_macro']:.4f}\")\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model, f'./ep{ep}.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For test set predictions, you can write perform evaluation simlar to #TODO5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6v/xp8z9pv1071bn0d5bykfn4200000gn/T/ipykernel_9928/371170967.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model = torch.load('./ep2.ckpt')\n",
      "Testing: 100%|██████████| 616/616 [01:24<00:00,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Results:\n",
      "Spearman Correlation: 0.8246\n",
      "Accuracy: 0.8746\n",
      "F1 Macro: 0.8664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load test dataset\n",
    "test_dataset = load_dataset(\"sem_eval_2014_task_1\", split=\"test\", cache_dir=\"./cache/\")\n",
    "\n",
    "# Create test dataloader\n",
    "dl_test = DataLoader(\n",
    "   test_dataset,\n",
    "   batch_size=validation_batch_size,\n",
    "   shuffle=False,\n",
    "   collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# Load best model\n",
    "best_model = torch.load('./ep2.ckpt')\n",
    "best_model.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_test(model, dataloader):\n",
    "   pbar = tqdm(dataloader)\n",
    "   pbar.set_description(\"Testing\")\n",
    "   all_rel_preds = []\n",
    "   all_rel_true = []\n",
    "   all_ent_preds = []\n",
    "   all_ent_true = []\n",
    "   \n",
    "   for batch in pbar:\n",
    "       input_ids, attention_mask, token_type_ids, rel_scores, ent_labels = [\n",
    "           x.to(device) for x in batch\n",
    "       ]\n",
    "       \n",
    "       rel_pred, ent_pred = model(\n",
    "           input_ids=input_ids,\n",
    "           attention_mask=attention_mask, \n",
    "           token_type_ids=token_type_ids\n",
    "       )\n",
    "       \n",
    "       all_rel_preds.extend(rel_pred.squeeze().cpu().tolist())\n",
    "       all_rel_true.extend(rel_scores.cpu().tolist())\n",
    "       all_ent_preds.extend(ent_pred.argmax(dim=-1).cpu().tolist())\n",
    "       all_ent_true.extend(ent_labels.cpu().tolist())\n",
    "   \n",
    "   # Calculate metrics\n",
    "   rel_preds = torch.tensor(all_rel_preds)\n",
    "   rel_true = torch.tensor(all_rel_true)\n",
    "   ent_preds = torch.tensor(all_ent_preds)\n",
    "   ent_true = torch.tensor(all_ent_true)\n",
    "   \n",
    "   spearman = spc(rel_preds, rel_true)\n",
    "   accuracy = acc(ent_preds, ent_true)\n",
    "   f1_macro = f1(ent_preds, ent_true)\n",
    "   \n",
    "   return {\n",
    "       'spearman': spearman.item(),\n",
    "       'accuracy': accuracy.item(),\n",
    "       'f1_macro': f1_macro.item()\n",
    "   }\n",
    "\n",
    "# Run predictions\n",
    "test_metrics = predict_test(best_model, dl_test)\n",
    "print(\"\\nTest Set Results:\")\n",
    "print(f\"Spearman Correlation: {test_metrics['spearman']:.4f}\")\n",
    "print(f\"Accuracy: {test_metrics['accuracy']:.4f}\") \n",
    "print(f\"F1 Macro: {test_metrics['f1_macro']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
